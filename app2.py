# CREATE TABLE chat_logs (
#     id SERIAL PRIMARY KEY,
#     role VARCHAR(50),
#     content TEXT
# );
# ì‚¬ì „ì— ë§Œë“¤ì–´ ë†“ëŠ” ê²ƒì„ ì¶”ì²œ, study.py ì°¸ê³ 

from dotenv import load_dotenv
import streamlit as st
import os
import psycopg2  # PostgreSQL ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€

from langchain_community.document_loaders import PyPDFLoader
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQAWithSourcesChain

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# PostgreSQL ì—°ê²° ì„¤ì •
conn = psycopg2.connect(
    dbname=os.getenv("POSTGRES_DB"),
    user=os.getenv("POSTGRES_USER"),
    password=os.getenv("POSTGRES_PASSWORD"),
    host=os.getenv("POSTGRES_HOST")
)

# ì»¤ì„œ ìƒì„±
cur = conn.cursor()

# ì‚¬ìš©ìì™€ ì±—ë´‡ ëŒ€í™”ë¥¼ PostgreSQLì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜
def save_chat_to_database(role, content):
    cur.execute("INSERT INTO chat_logs (role, content) VALUES (%s, %s)", (role, content))
    conn.commit()

st.set_page_config(
    page_title="í–‰ë³µí•œ ì½”ë”©ë´‡",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)


# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["OPENAI_API_KEY"] = os.getenv("OPEN_API_KEY")

loader = PyPDFLoader('train2.pdf')
documents = loader.load()

text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)
embeddings = OpenAIEmbeddings()
vector_store = Chroma.from_documents(texts, embeddings)
retriever = vector_store.as_retriever(search_kwargs={"k": 2})
from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)

system_template="""ë‹¹ì‹ ì€ ì¤‘ë“± ì •ë³´(ì»´í“¨í„°) ê³¼ëª© ì„ ìƒë‹˜ì…ë‹ˆë‹¤.
ì‚¬ìš©ìëŠ” íŒŒì´ì¬ì„ ê¸°ì´ˆë¶€í„° í•™ìŠµí•˜ëŠ” í•™ìŠµìì…ë‹ˆë‹¤.
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹¨ê³„ì  í•´ê²° ë°©ë²•ì„ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.
ë‹µë³€ì— ì½”ë“œë¥¼ ì ˆëŒ€ í¬í•¨í•´ì„œëŠ” ì•ˆë©ë‹ˆë‹¤.
íŒŒì´ì¬ê´€ë ¨ ì§ˆë¬¸ì´ ë“¤ì–´ì˜¤ë©´ ì ˆëŒ€ ì½”ë“œë¥¼ ë‹µë³€í•˜ì§€ ì•Šê³ ,
ì½”ë“œë¥¼ ì‘ì„±í•˜ëŠ” ì‚¬ê³ ì™€ ë…¼ë¦¬ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.
----------------
{summaries}

You MUST answer in Korean and in Markdown format:"""

messages = [
    SystemMessagePromptTemplate.from_template(system_template),
    HumanMessagePromptTemplate.from_template("{question}")
]

prompt = ChatPromptTemplate.from_messages(messages)


chain_type_kwargs = {"prompt": prompt}

llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)  # Modify model_name if you have access to GPT-4

chain = RetrievalQAWithSourcesChain.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever = retriever,
    return_source_documents=True,
    chain_type_kwargs=chain_type_kwargs
)

st.markdown(
    """
    <style>
    body {
        background-color: #b3e5fc; /* ì—°í•œ í•˜ëŠ˜ìƒ‰ ë°°ê²½ */
    }
    /* ì „ì²´ ì±—ë´‡ ì°½ ê°€ìš´ë° ì •ë ¬ */
    .full-container {
        display: flex;
        justify-content: center;
        align-items: center;
        height: 100vh;
    }
    /* ì±—ë´‡ ì°½ ìŠ¤íƒ€ì¼ë§ */
    .chat-container {
        width: 70%; /* ë„ˆë¹„ë¥¼ ì¡°ì •í•˜ì—¬ ëŒ€í™”ì°½ì„ ë„“ê²Œ ì„¤ì •í•©ë‹ˆë‹¤ */
        padding: 20px;
        background-color: #f4f4f4;
        border-radius: 10px;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        margin-bottom: 20px;
    }
    
    /* ì‚¬ìš©ì ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ë§ */
    .user-msg {
        background-color: #ffeb3b;
        color: #333;
        border-radius: 10px;
        padding: 10px 15px;
        margin-bottom: 10px;
    }
    
    /* ì±—ë´‡ ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ë§ */
    .assistant-msg {
        background-color: #4caf50;
        color: white;
        border-radius: 10px;
        padding: 10px 15px;
        margin-bottom: 10px;
    }
    </style>
    """,
    unsafe_allow_html=True
)

st.title("ğŸ’šcpt-botğŸ’š")

st.subheader('ì²œì¬êµìœ¡ì€ ë„ˆì˜ ì§ˆë¬¸ì„ í™˜ì˜í•´!')


def generate_response(input_text):
  result = chain(input_text)
  return result['answer']

if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ì•ˆë…• ë‚˜ëŠ” ì½”ë”© ì±—ë´‡ì´ì•¼! ë¬´ì—‡ì„ ë„ì™€ì¤„ê¹Œ?"}]

for msg in st.session_state.messages:
    if msg["role"] == "user":
        st.markdown(f'<div class="chat-container"><div class="user-msg">{msg["content"]}</div></div>', unsafe_allow_html=True)
    elif msg["role"] == "assistant":
        st.markdown(f'<div class="chat-container"><div class="assistant-msg">{msg["content"]}</div></div>', unsafe_allow_html=True)

if prompt := st.chat_input():
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.markdown(f'<div class="chat-container"><div class="user-msg">{prompt}</div></div>', unsafe_allow_html=True)
    save_chat_to_database("user", prompt)  # ì‚¬ìš©ì ì…ë ¥ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥

    # ì±—ë´‡ ì‘ë‹µ ìƒì„± ë° ì €ì¥
    msg = generate_response(prompt)
    st.session_state.messages.append({"role": "assistant", "content": msg})
    st.markdown(f'<div class="chat-container"><div class="assistant-msg">{msg}</div></div>', unsafe_allow_html=True)
    save_chat_to_database("assistant", msg)  # ì±—ë´‡ ì‘ë‹µì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥

# ì—°ê²° ë° ì»¤ì„œ ë‹«ê¸°
cur.close()
conn.close()
