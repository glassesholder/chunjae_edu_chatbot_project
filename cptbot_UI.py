import os
import streamlit as st
from streamlit_pills import pills

from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import PyPDFLoader
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.chains import RetrievalQAWithSourcesChain
from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate

from to_database import save_chat_to_database


#ê¸°ë³¸ì ì¸ chatbot uië¥¼ ìœ„í•œ style ì‘ì„±
def CPT(cur, conn):
    st.markdown(
    """
    <style>
    body {
        background-color: #b3e5fc; /* ì—°í•œ í•˜ëŠ˜ìƒ‰ ë°°ê²½ */
    }
    /* ì „ì²´ ì±—ë´‡ ì°½ ê°€ìš´ë° ì •ë ¬ */
    .full-container {
        display: flex;
        justify-content: center;
        align-items: center;
        height: 100vh;
    }
    /* ì±—ë´‡ ì°½ ìŠ¤íƒ€ì¼ë§ */
    .chat-container {
        width: 90%; /* ë„ˆë¹„ë¥¼ ì¡°ì •í•˜ì—¬ ëŒ€í™”ì°½ì„ ë„“ê²Œ ì„¤ì •í•©ë‹ˆë‹¤ */
        padding: 20px;
        background-color: #f4f4f4;
        border-radius: 10px;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        margin-bottom: 20px;
    }

    .chat-container2 {
        width: 90%; /* ë„ˆë¹„ë¥¼ ì¡°ì •í•˜ì—¬ ëŒ€í™”ì°½ì„ ë„“ê²Œ ì„¤ì •í•©ë‹ˆë‹¤ */
        padding: 20px;
        background-color: #f4f4f4;
        border-radius: 10px;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        margin-bottom: 20px;
        float: right;
    }
    
    /* ì‚¬ìš©ì ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ë§ */
    .user-msg {
        background-color: #fff9c4;
        color: #333;
        border-radius: 10px;
        padding: 10px 15px;
        margin-bottom: 10px;
    }
    
    /* ì±—ë´‡ ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ë§ */
    .assistant-msg {
        background-color: #aaf0d1;
        color: black;
        border-radius: 10px;
        padding: 10px 15px;
        margin-bottom: 10px;
    }
    </style>
    """,
    unsafe_allow_html=True
    )

    os.environ["OPENAI_API_KEY"] = os.getenv("OPEN_API_KEY")

    # PDF íŒŒì¼ ë¡œë“œ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ
    loader = PyPDFLoader('./files/train.pdf')
    documents = loader.load()

    # í…ìŠ¤íŠ¸ë¥¼ ì ì ˆí•œ í¬ê¸°ë¡œ ë‚˜ëˆ„ê¸°
    text_splitter = CharacterTextSplitter(chunk_size=1, chunk_overlap=0)
    texts = text_splitter.split_documents(documents)

    # ë¬¸ì¥ì„ ë²¡í„°ë¡œ ë³€í™˜í•œ ë’¤, vector_storeì— ì €ì¥
    embeddings = OpenAIEmbeddings()
    vector_store = Chroma.from_documents(texts, embeddings)
    retriever = vector_store.as_retriever(search_kwargs={"k": 1})

    # ì‚¬ê³ ë ¥ì„ ê¸°ë¥´ê¸° ìœ„í•œ ì±—ë´‡ system_prompt ì„¤ì •
    system_template_hint = """ë‹¹ì‹ ì€ ì¤‘ë“± ì •ë³´(ì»´í“¨í„°) ê³¼ëª© ì„ ìƒë‹˜ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìëŠ” ì¤‘í•™êµ ë˜ëŠ” ê³ ë“±í•™êµì˜ ì •ê·œêµê³¼ê³¼ì •ì„ í†µí•´ ì§€ê¸ˆ íŒŒì´ì¬ì„ ê¸°ì´ˆë¶€í„° í•™ìŠµí•˜ê³  ìˆìŠµë‹ˆë‹¤.
    ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹¨ê³„ì  í•´ê²° ë°©ë²•ì„ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.
    ë‹µë³€ì— ì½”ë“œë¥¼ ì ˆëŒ€ í¬í•¨í•´ì„œëŠ” ì•ˆë©ë‹ˆë‹¤.
    íŒŒì´ì¬ê´€ë ¨ ì§ˆë¬¸ì´ ë“¤ì–´ì˜¤ë©´ ì ˆëŒ€ ì½”ë“œë¥¼ ë‹µë³€í•˜ì§€ ì•Šê³ ,
    ì½”ë“œë¥¼ ì‘ì„±í•˜ëŠ” ì‚¬ê³ ì™€ ë…¼ë¦¬ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.
    ê°€ë…ì„±ì„ ìœ„í•´ íŒíŠ¸ëŠ” í•œì¤„ì”©,ë²ˆí˜¸ë¥¼ ë§¤ê²¨ ì•Œë ¤ì£¼ì„¸ìš”.
    
    ----------------
    {summaries}
    You MUST answer in Korean and in Markdown format:"""
    messages_hint = [
        SystemMessagePromptTemplate.from_template(system_template_hint),
        HumanMessagePromptTemplate.from_template("{question}")
    ]

    prompt_hint = ChatPromptTemplate.from_messages(messages_hint)
    chain_type_kwargs_hint = {"prompt": prompt_hint}
    llm = ChatOpenAI(model_name="ft:gpt-3.5-turbo-0125:text-analysis::9FGo0Rf4", temperature=0)

    #ì‚¬ê³ ë ¥ì„ ê¸°ë¥´ê¸° ìœ„í•œ ì±—ë´‡ ìƒì„±
    chain_hint = RetrievalQAWithSourcesChain.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=True,
        chain_type_kwargs=chain_type_kwargs_hint
    )

    # ì •ë‹µ ì½”ë“œ ì œê³µì„ ìœ„í•œ ì±—ë´‡ system_prompt ì„¤ì •
    system_template_answer = """ë‹¹ì‹ ì€ ì¤‘ë“± ì •ë³´(ì»´í“¨í„°) ê³¼ëª© ì„ ìƒë‹˜ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìëŠ” ì¤‘í•™êµ ë˜ëŠ” ê³ ë“±í•™êµì˜ ì •ê·œêµê³¼ê³¼ì •ì„ í†µí•´ ì§€ê¸ˆ íŒŒì´ì¬ì„ ê¸°ì´ˆë¶€í„° í•™ìŠµí•˜ê³  ìˆìŠµë‹ˆë‹¤.
    ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì˜¤ì§ ì •ë‹µ python ì½”ë“œë§Œ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.
    íŒŒì´ì¬ê´€ë ¨ ì§ˆë¬¸ì´ ë“¤ì–´ì˜¤ë©´ ì ˆëŒ€ í•œê¸€ë¡œ ì„¤ëª…í•˜ì§€ ì•Šê³ ,
    python ì½”ë“œë§Œ ì•Œë ¤ì¤˜ì„œ í•™ìŠµì„ ë„ì™€ì£¼ì„¸ìš”.
    ì˜ˆì‹œ ì½”ë“œê°€ í•„ìš”í•˜ë‹¤ë©´ ì˜ˆì‹œì½”ë“œê¹Œì§€ ì œê³µí•´ì£¼ì„¸ìš”.
    ----------------
    {summaries}
    You MUST answer in python code : """

    messages_answer = [
        SystemMessagePromptTemplate.from_template(system_template_answer),
        HumanMessagePromptTemplate.from_template("{question}")
    ]

    prompt_answer = ChatPromptTemplate.from_messages(messages_answer)
    chain_type_kwargs_answer = {"prompt": prompt_answer}

     # ì •ë‹µ ì½”ë“œ ì œê³µì„ ìœ„í•œ ì±—ë´‡ ìƒì„±
    chain_answer = RetrievalQAWithSourcesChain.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=True,
        chain_type_kwargs=chain_type_kwargs_answer
    )
    user_id = st.session_state['user_id']

    def generate_response_hint(input_text):
        result = chain_hint(input_text)
        return result['answer']
    def generate_response_answer(input_text):
        result = chain_answer(input_text)
        return result['answer']

    col1, col2 = st.columns([1,16])

    with col1:
        # ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¡°ì •í•˜ì—¬ ì»¬ëŸ¼ì— ë§ê²Œ ì¡°í™”ë¡­ê²Œ í‘œì‹œ
        st.image("./images/chatbot.png", width=64)  # ì´ë¯¸ì§€ì˜ widthë¥¼ ì¡°ì •

    with col2:
        # HTMLê³¼ CSSë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸€ì ê°„ê²© ì¡°ì •
        st.markdown("""
        <style>
        .login-text {
            margin-top: -10px;  # ê¸€ì ê°„ê²© ì¡°ì •
        }
        </style>
        <h1 class="login-text">CPT(Chunjae Python Tutor)</h1>
        """, unsafe_allow_html=True)

    st.caption('CPT(Chunjae Python Tutor)ë´‡ì€ GPT-3.5ë¥¼ í•™ìŠµì‹œí‚¨ ê²°ê³¼ë¡œ ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤.')
    st.divider()
    st.header(f'{user_id}ë‹˜, ë°˜ê°€ì›Œìš”:wave:')
    # st.markdown(":red[íŒŒì´ì¬ìœ¼ë¡œ 00í•˜ëŠ” ë°©ë²•ì´ ê¶ê¸ˆí•´.] ë˜ëŠ” :red[00í•˜ëŠ” ì½”ë“œë¥¼ ë§Œë“¤ê³  ì‹¶ì–´.]ì™€ ê°™ì´ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”!")
    
    # cptë´‡ì´ ë§í•´ì£¼ëŠ” ì²« ë¬¸ì¥ ìƒì„±
    if "messages" not in st.session_state:
        st.session_state["messages"] = [{"role": "assistant", "content": "ê¶ê¸ˆì¦ í•´ê²°ì‚¬ CPTë´‡ì´ì—ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"}]
        save_chat_to_database(cur, conn, user_id ,"assistant", "ê¶ê¸ˆì¦ í•´ê²°ì‚¬ CPTë´‡ì´ì—ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")
    
    # cptë´‡ì´ ì‘ë‹µí•œ ì§ì „ ì‘ë‹µì„ ì €ì¥í•  ê³µê°„
    if "last_question" not in st.session_state:
        st.session_state["last_question"] = ""

    # cptë´‡ê³¼ ë‚˜ëˆˆ ì´ì „ ëŒ€í™” ê°€ì ¸ì™€ì„œ ì±„íŒ…ì°½ì— í‘œì‹œ(ì¦‰, ê·¸ ì „ì— ìˆë˜ ê²ƒ)
    for msg in st.session_state.messages:
        if msg["role"] == "user":
            st.markdown(f'<div class="chat-container2"><div class="user-msg">{msg["content"]}</div></div>', unsafe_allow_html=True)
        elif msg["role"] == "assistant":
            if "```" in msg['content']:
                st.chat_message("assistant").write(msg['content'])
            else:
                st.markdown(f'<div class="chat-container"><div class="assistant-msg">{msg["content"]}</div></div>', unsafe_allow_html=True)

    # ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê·¸ì— ë”°ë¥¸ ì‘ë‹µ ì¶œë ¥
    if prompt := st.chat_input("íŒŒì´ì¬ìœ¼ë¡œ 00í•˜ëŠ” ë²• ì•Œë ¤ì¤˜"):  # ë§Œì•½ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚´ìš©ì´ ìˆë‹¤ë©´ 
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.markdown(f'<div class="chat-container2"><div class="user-msg">{prompt}</div></div>', unsafe_allow_html=True)
        save_chat_to_database(cur, conn, user_id, "user", prompt)
        with st.spinner('ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤ğŸ’¨'):
            msg = generate_response_hint(prompt)

        st.session_state.messages.append({"role": "assistant", "content": msg})
        st.markdown(f'<div class="chat-container"><div class="assistant-msg">{msg}</div></div>', unsafe_allow_html=True)

        st.session_state["last_question"] = msg # ì§ì „ ì§ˆë¬¸ ì €ì¥
        selected = pills("Feedback please", ["ë§Œì¡±í•´ìš”", "ìŠ¤íƒ€ì¼ì´ ë§ˆìŒì— ì•ˆ ë“¤ì–´ìš”", "ì´í•´ê°€ ì•ˆ ë¼ìš”", "ì½”ë“œê°€ í‹€ë ¸ì–´ìš”"], ["ğŸ‘", "ğŸ‘", "â“", "âŒ"], index=False)
        save_chat_to_database(cur, conn, user_id, 'assistant', msg, selected)

    # ë²„íŠ¼ì„ ìœ„í•œ CSS ìŠ¤íƒ€ì¼ì„ ì •ì˜í•©ë‹ˆë‹¤.
    button_style = """
        <style>
            .stButton>button {
                width: 60%;
            }
        </style>
    """

    # CSS ìŠ¤íƒ€ì¼ì„ Streamlitì— ì ìš©í•©ë‹ˆë‹¤.
    st.markdown(button_style, unsafe_allow_html=True)

    # "íŒíŠ¸ í•œ ë²ˆ ë” ë³¼ë˜ìš”" ë²„íŠ¼ ë¡œì§
    if st.button("íŒíŠ¸ í•œ ë²ˆ ë” ë³¼ë˜ìš”:bulb:"):
        if st.session_state["last_question"]:  # ì§ì „ ì§ˆë¬¸ì´ ìˆì„ ê²½ìš°ì—ë§Œ ì‘ë™
            prompt = st.session_state["last_question"]  # ì§ì „ ì§ˆë¬¸ì„ ë‹¤ì‹œ ì‚¬ìš©
            st.session_state.messages.append({"role": "user", "content":  "íŒíŠ¸ í•œ ë²ˆ ë” ë³¼ë˜ìš”!"})
            save_chat_to_database(cur, conn, user_id, "user", "íŒíŠ¸ í•œ ë²ˆ ë” ë³¼ë˜ìš”!")
            with st.spinner('ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤ğŸ’¨'):
                msg = generate_response_hint(prompt + ' ì¡°ê¸ˆ ë” ìì„¸í•˜ê²Œ ì•Œë ¤ì¤˜.')  # ì§ì „ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€(íŒíŠ¸) ìƒì„±

            st.session_state.messages.append({"role": "assistant", "content": msg})
            st.session_state["last_question"] = msg


            st.markdown(f'<div class="chat-container2"><div class="user-msg">{"íŒíŠ¸ í•œ ë²ˆ ë” ë³¼ë˜ìš”!"}</div></div>', unsafe_allow_html=True)

            st.markdown(f'<div class="chat-container"><div class="assistant-msg">{msg}</div></div>', unsafe_allow_html=True)
            selected = pills("Feedback please", ["ë§Œì¡±í•´ìš”", "ìŠ¤íƒ€ì¼ì´ ë§ˆìŒì— ì•ˆ ë“¤ì–´ìš”", "ì´í•´ê°€ ì•ˆ ë¼ìš”", "ì½”ë“œê°€ í‹€ë ¸ì–´ìš”"], ["ğŸ‘", "ğŸ‘", "â“", "âŒ"], index=False)
            save_chat_to_database(cur, conn, user_id, "assistant", msg, selected)
        else:
            st.markdown(f'<div class="chat-container"><div class="assistant-msg">{"ì§ì „ì— ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."}</div></div>', unsafe_allow_html=True)

    # "ì •ë‹µ ì½”ë“œë¥¼ ì•Œê³  ì‹¶ì–´ìš”" ë²„íŠ¼ ë¡œì§
    if st.button("ì •ë‹µ ì½”ë“œë¥¼ ì•Œê³  ì‹¶ì–´ìš”:heavy_check_mark:"):
        if st.session_state["last_question"]:  # ì§ì „ ì§ˆë¬¸ì´ ìˆì„ ê²½ìš°ì—ë§Œ ì‘ë™
            prompt = st.session_state["last_question"]  # ì§ì „ ì§ˆë¬¸ì„ ë‹¤ì‹œ ì‚¬ìš©
            st.session_state.messages.append({"role": "user", "content":  "ì •ë‹µ ì½”ë“œë¥¼ ì•Œê³  ì‹¶ì–´ìš”!"})
            save_chat_to_database(cur, conn, user_id, "user", "ì •ë‹µ ì½”ë“œë¥¼ ì•Œê³  ì‹¶ì–´ìš”!")

            with st.spinner('ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤ğŸ’¨'):
                msg = generate_response_answer(prompt)  # ì§ì „ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€(íŒíŠ¸) ìƒì„±
            st.session_state.messages.append({"role": "assistant", "content": msg})


            st.markdown(f'<div class="chat-container2"><div class="user-msg">{"ì •ë‹µ ì½”ë“œë¥¼ ì•Œê³  ì‹¶ì–´ìš”!"}</div></div>', unsafe_allow_html=True)
            st.chat_message("assistant").write(msg)
            selected = pills("Feedback please", ["ë§Œì¡±í•´ìš”", "ìŠ¤íƒ€ì¼ì´ ë§ˆìŒì— ì•ˆ ë“¤ì–´ìš”", "ì´í•´ê°€ ì•ˆ ë¼ìš”", "ì½”ë“œê°€ í‹€ë ¸ì–´ìš”"], ["ğŸ‘", "ğŸ‘", "â“", "âŒ"], index=False)
            save_chat_to_database(cur, conn, user_id, "assistant", msg, selected)
        else:
            st.markdown(f'<div class="chat-container"><div class="assistant-msg">{"ì§ì „ì— ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."}</div></div>', unsafe_allow_html=True)